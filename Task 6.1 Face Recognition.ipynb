{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 - Collect dataset by clicking your pics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:11: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:11: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<ipython-input-5-ad8562117391>:11: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if faces is ():\n"
     ]
    }
   ],
   "source": [
    "import cv2, numpy\n",
    "\n",
    "#Loading HAAR face classifier\n",
    "face_classifier=cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Function detects faces and returns the cropped face. If no face detected, it returns the input image\n",
    "def face_extractor(img):\n",
    "    gray=cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces=face_classifier.detectMultiScale(img, scaleFactor=1.3, minNeighbors=5)\n",
    "    \n",
    "    if faces is ():\n",
    "        return None\n",
    "        \n",
    "    # Crop all faces found\n",
    "    for (x,y,w,h) in faces:\n",
    "        cropped_face=img[y:y+h,x:x+w]\n",
    "    return cropped_face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Webcam\n",
    "cap=cv2.VideoCapture(0)\n",
    "count=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "Collecting Samples Complete\n"
     ]
    }
   ],
   "source": [
    "# Collect 100 samples of your face from webcam input\n",
    "while True:\n",
    "    ret,frame=cap.read()\n",
    "    \n",
    "    if face_extractor(frame) is not None:\n",
    "        count+=1\n",
    "        face=cv2.resize(face_extractor(frame), (200,200))\n",
    "        face=cv2.cvtColor(face,cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Save file in specified directory with unique name\n",
    "        file_name_path='../faces/user2/' + str(count) + '.jpg'\n",
    "        cv2.imwrite(file_name_path,face)\n",
    "        \n",
    "        # Put count on images and display live count\n",
    "        cv2.putText(face, str(count), (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,(0,255,0), 2 )\n",
    "        cv2.imshow(\"face cropper\", face)\n",
    "        \n",
    "    else:\n",
    "        print(\"face not found\")\n",
    "        \n",
    "    if cv2.waitKey(2) == 13 or count == 100:\n",
    "        break\n",
    "        \n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()      \n",
    "print(\"Collecting Samples Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 - Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2, numpy, os\n",
    "\n",
    "\n",
    "# Get the training data we previously made\n",
    "data_path=\"../faces/user2/\"\n",
    "if not os.path.exists(data_path):\n",
    "    os.mkdir(data_path)\n",
    "#print(os.listdir())\n",
    "\n",
    "onlyfiles = [f for f in os.listdir(data_path) if os.path.isfile(os.path.join(data_path, f))]\n",
    "\n",
    "#print(onlyfiles)\n",
    "#print(type(onlyfiles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create arrays for training data and labels\n",
    "Training_Data, Labels = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open training images in our datapath. Create a numpy array for training data\n",
    "for i,files in enumerate(onlyfiles):\n",
    "    image_path=data_path + onlyfiles[i]\n",
    "    images = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    Training_Data.append(numpy.asarray(images,dtype=numpy.uint8))\n",
    "    Labels.append(i)\n",
    "    \n",
    "# Create a numpy array for both training data and labels\n",
    "Labels=numpy.asarray(Labels,dtype=numpy.int32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your name: K\n"
     ]
    }
   ],
   "source": [
    "name=input(\"Enter your name: \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"Model for \"+name+\" trained successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model K trained successfully\n"
     ]
    }
   ],
   "source": [
    "# Let's train our model \n",
    "model_name=cv2.face_LBPHFaceRecognizer.create()\n",
    "model_name.train(numpy.asarray(Training_Data),numpy.asarray(Labels))\n",
    "print(\"Model \"+name+\" trained successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 - Run Our Facial Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2, numpy, os\n",
    "face_classifier=cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:6: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:6: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<ipython-input-18-37fbe04b0d40>:6: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if faces is ():\n"
     ]
    }
   ],
   "source": [
    "def face_detector(img,size=0.5):\n",
    "    \n",
    "    # Convert image to grayscale\n",
    "    gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces=face_classifier.detectMultiScale(gray,scaleFactor=1.3, minNeighbors=5)\n",
    "    if faces is ():\n",
    "        return img, []\n",
    "    \n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,255),2)\n",
    "        roi=img[y:y+h,x:x+w]\n",
    "        roi=cv2.resize(roi,(200,200))\n",
    "    return img, roi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18, 31.147849112411205)\n",
      "Content-Type: multipart/mixed; boundary=\"===============5876453558387367785==\"\n",
      "MIME-Version: 1.0\n",
      "\n",
      "--===============5876453558387367785==\n",
      "\n",
      "--===============5876453558387367785==--\n",
      "\n",
      "enter the hr, min, sec(seperated by space in 24 hr format)17 37 20\n",
      "17 37 20\n",
      "In 28 seconds web.whatsapp.com will open and after 20 seconds message will be delivered\n"
     ]
    }
   ],
   "source": [
    "# Open Webcam\n",
    "cap=cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret,frame=cap.read()\n",
    "    image, face = face_detector(frame)\n",
    "    try:\n",
    "        face=cv2.cvtColor(face,cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Pass face to prediction model\n",
    "        # \"results\" comprises of a tuple containing the label and the confidence value\n",
    "        results=model_name.predict(face)\n",
    "        print(results)\n",
    "        \n",
    "        if results[1]<500:\n",
    "            confidence=int(100*(1-results[1]/400))\n",
    "            display_string=str(confidence)+\"% confident it is \"+name\n",
    "            \n",
    "        cv2.putText(image,display_string,(100,200),cv2.FONT_HERSHEY_COMPLEX,1, (255,120,150),2)\n",
    "        \n",
    "        if confidence > 80:\n",
    "            cv2.putText(image,\"Hey \"+name,(250,450), cv2.FONT_HERSHEY_COMPLEX,1, (0,255,0),2)\n",
    "            cv2.imshow(\"face Recognition\", image)\n",
    "            ############ CODE TO AUTOMATE: HERE ###########################\n",
    "            # 1. Sending mail :Code starts here \n",
    "            import smtplib, ssl, credentials\n",
    "            from email.mime.text import MIMEText\n",
    "            from email.mime.base import MIMEBase\n",
    "            from email.mime.multipart import MIMEMultipart\n",
    "            from email import encoders\n",
    "\n",
    "\n",
    "            receivers=['krithikasharma2129@gmail.com']\n",
    "            body=\"Happy coding!!\"\n",
    "\n",
    "            msg=MIMEMultipart()\n",
    "            print(msg)\n",
    "            msg[\"Subject\"]=\"This is face of \"+name\n",
    "            msg['From']= credentials.mail\n",
    "            msg['To']=\",\".join(receivers)\n",
    "\n",
    "            s=smtplib.SMTP_SSL(host=\"smtp.gmail.com\",port=465)\n",
    "            s.login(user=credentials.mail, password=credentials.passwd)\n",
    "            s.sendmail(credentials.mail,receivers,msg.as_string())\n",
    "            s.quit()\n",
    "            # sending mail: Code ends here\n",
    "            \n",
    "            # 2. Sending Whatsapp message: Code starts here \n",
    "            import pywhatkit\n",
    "            hr, mi, sec=input(\"enter the hr, min, sec(seperated by space in 24 hr format)\").split()\n",
    "            print(int(hr),int(mi),int(sec))\n",
    "            pywhatkit.sendwhatmsg(\"+917386338720\",\"Hi this is automated msg sent using python!!\",int(hr),int(mi),int(sec))\n",
    "            # Sending Whatsapp message: Code ends here\n",
    "            \n",
    "            break\n",
    "            \n",
    "            \n",
    "        else:\n",
    "            cv2.putText(image,\"I don't know who r u\",(250,450),cv2.FONT_HERSHEY_COMPLEX,1,(0,0,255),2)\n",
    "            cv2.imshow(\"Face Recognition\", image)\n",
    "            \n",
    "    except:\n",
    "        cv2.putText(image, \"No Face Found\", (220, 120) , cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "        cv2.putText(image, \"looking for face\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "        cv2.imshow('Face Recognition', image )\n",
    "        pass\n",
    "        if cv2.waitKey(20) == 13: #13 is the Enter Key\n",
    "            break\n",
    "        \n",
    "    cap.release()\n",
    "    \n",
    "    cv2.destroyAllWindows()     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
